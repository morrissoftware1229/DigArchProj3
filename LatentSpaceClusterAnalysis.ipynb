{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the movie embeddings\n",
    "import json\n",
    "movie_embeddings = json.load(open(\"honey_i_shrunk_the_kids_movie_embeddings_1_second.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get length of movie embeddings\n",
    "print(len(movie_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the opening credits\n",
    "movie_embeddings = movie_embeddings[163:len(movie_embeddings)]\n",
    "\n",
    "# Cleaning the closing credits\n",
    "movie_embeddings = movie_embeddings[0:5222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined path to images\n",
    "from IPython.display import Image, display\n",
    "image_root = 'thumbnails_folder2large/'\n",
    "\n",
    "# Iterate through the input list\n",
    "import numpy as np\n",
    "def euclidean_distance(array1, array2):\n",
    "    array1_np = np.array(array1)\n",
    "    array2_np = np.array(array2)\n",
    "    distance = np.linalg.norm(array1_np - array2_np)\n",
    "    return distance\n",
    "\n",
    "target_index = 4000\n",
    "target = movie_embeddings[target_index]\n",
    "index_to_distance = []\n",
    "\n",
    "for emb in movie_embeddings:\n",
    "    current_dist = euclidean_distance(emb[\"embedding\"], target[\"embedding\"])\n",
    "    index_to_distance.append(current_dist)\n",
    "\n",
    "# Sort the index_to_distance array and keep track of the original indexes\n",
    "sorted_indexes = np.argsort(index_to_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using t-SNE to embed the vectors into 2D\n",
    "from sklearn.manifold import TSNE\n",
    "embeddings = np.array([vector['embedding'] for vector in movie_embeddings])\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_vectors = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing KMeans clustering with k=12\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=12, random_state=42)\n",
    "clusters = kmeans.fit_predict(embedded_vectors)\n",
    "\n",
    "# Extracting numbers from file names for labels\n",
    "import re\n",
    "labels = [re.search(r'\\d+', vector['input']).group() for vector in movie_embeddings]\n",
    "\n",
    "# Plotting the embedded vectors with cluster coloring\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "sns.scatterplot(x=embedded_vectors[:, 0], y=embedded_vectors[:, 1], hue=clusters, palette='bright', legend='full', s=100)\n",
    "for i, vec in enumerate(embedded_vectors):\n",
    "    plt.text(vec[0] + 0.02, vec[1] + 0.02, labels[i], fontsize=6)  # Adding labels\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('t-SNE Embedded Vectors with KMeans Clustering (k=12)')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Initialize 12 lists to store indexes for each cluster\n",
    "cluster_indexes = [[] for _ in range(12)]\n",
    "\n",
    "# Populate lists with indexes\n",
    "for i, cluster in enumerate(clusters):\n",
    "    cluster_indexes[cluster].append(i)\n",
    "\n",
    "# Assign images to cluster indices\n",
    "for i in range(0,12):\n",
    "    print(\"cluster\",i,len(cluster_indexes[i]))\n",
    "\n",
    "# Create a list of cluster assignments for each vector\n",
    "cluster_labels = [f'Cluster {cluster}' for cluster in clusters]\n",
    "\n",
    "# Plotting the scatter plot\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "sns.scatterplot(x=np.arange(len(movie_embeddings)), y=cluster_labels, hue=cluster_labels, palette='bright', legend='full', s=100)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Cluster')\n",
    "plt.title('Cluster Assignments of Vectors')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image from the cluster\n",
    "print(\"Displaying Example Images from Cluster for Familiarization.\")\n",
    "for i in cluster_indexes[0][0:9]:\n",
    "    image_path = image_root+movie_embeddings[i][\"input\"]\n",
    "    display(Image(filename=image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing a target frame for daughter\n",
    "target_index = 1043\n",
    "target = movie_embeddings[target_index]\n",
    "index_to_Amy = []\n",
    "image_path = image_root+movie_embeddings[target_index][\"input\"]\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "# Finding index to distance of target frame\n",
    "for emb in movie_embeddings:\n",
    "    current_dist = euclidean_distance(emb[\"embedding\"], target[\"embedding\"])\n",
    "    index_to_Amy.append(current_dist)\n",
    "\n",
    "# Create a plot using Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=range(len(index_to_Amy)), y=index_to_Amy)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title(\"Distance from Target Over Film\")\n",
    "plt.show()\n",
    "\n",
    "# Choosing a target frame for neighbor's older son\n",
    "target_index = 1059\n",
    "target = movie_embeddings[target_index]\n",
    "index_to_Russ = []\n",
    "image_path = image_root+movie_embeddings[target_index][\"input\"]\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "# Finding index to distance of target frame\n",
    "for emb in movie_embeddings:\n",
    "    current_dist = euclidean_distance(emb[\"embedding\"], target[\"embedding\"])\n",
    "    index_to_Russ.append(current_dist)\n",
    "\n",
    "# Create a plot using Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=range(len(index_to_Russ)), y=index_to_Russ)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title(\"Distance from Target Over Film\")\n",
    "plt.show()\n",
    "\n",
    "# Choosing a target frame for neighbor's younger son\n",
    "target_index = 1062\n",
    "target = movie_embeddings[target_index]\n",
    "index_to_Ron = []\n",
    "image_path = image_root+movie_embeddings[target_index][\"input\"]\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "# Finding index to distance of target frame\n",
    "for emb in movie_embeddings:\n",
    "    current_dist = euclidean_distance(emb[\"embedding\"], target[\"embedding\"])\n",
    "    index_to_Ron.append(current_dist)\n",
    "\n",
    "# Create a plot using Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=range(len(index_to_Ron)), y=index_to_Ron)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title(\"Distance from Target Over Film\")\n",
    "plt.show()\n",
    "\n",
    "# Choosing a target frame for inventor's son\n",
    "target_index = 627\n",
    "target = movie_embeddings[target_index]\n",
    "index_to_Nick = []\n",
    "image_path = image_root+movie_embeddings[target_index][\"input\"]\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "# Finding index to distance of target frame\n",
    "for emb in movie_embeddings:\n",
    "    current_dist = euclidean_distance(emb[\"embedding\"], target[\"embedding\"])\n",
    "    index_to_Nick.append(current_dist)\n",
    "\n",
    "# Create a plot using Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=range(len(index_to_Nick)), y=index_to_Nick)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title(\"Distance from Target Over Film\")\n",
    "plt.show()\n",
    "\n",
    "# Finding lowest average distance\n",
    "import statistics\n",
    "average_to_Amy = statistics.mean(index_to_Amy)\n",
    "average_to_Russ = statistics.mean(index_to_Russ)\n",
    "average_to_Ron = statistics.mean(index_to_Ron)\n",
    "average_to_Nick = statistics.mean(index_to_Nick)\n",
    "print(f\"Average to Amy: {average_to_Amy}\")\n",
    "print(f\"Average to Russ: {average_to_Russ}\")\n",
    "print(f\"Average to Ron: {average_to_Ron}\")\n",
    "print(f\"Average to Nick: {average_to_Nick}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing how often the dog appears\n",
    "\n",
    "# Checking to make sure we have the right image\n",
    "print(\"Target Frame Printed Below\")\n",
    "target_index = 1469\n",
    "image_path = image_root+movie_embeddings[target_index][\"input\"]\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "# Filling indexes with distances\n",
    "target = movie_embeddings[target_index]\n",
    "index_to_distance = []\n",
    "for emb in movie_embeddings:\n",
    "    current_dist = euclidean_distance(emb[\"embedding\"], target[\"embedding\"])\n",
    "    index_to_distance.append(current_dist)\n",
    "\n",
    "# Sort the index_to_distance array and keep track of the original indexes\n",
    "sorted_indexes = np.argsort(index_to_distance)\n",
    "\n",
    "# Determining the new number of clusters\n",
    "number_of_clusters = 36\n",
    "\n",
    "# Convert using tSNE\n",
    "embeddings = np.array([vector['embedding'] for vector in movie_embeddings])\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_vectors = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Performing KMeans clustering with k=36\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=number_of_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embedded_vectors)\n",
    "\n",
    "# Extracting numbers from file names for labels\n",
    "labels = [re.search(r'\\d+', vector['input']).group() for vector in movie_embeddings]\n",
    "\n",
    "# Initialize 36 lists to store indexes for each cluster\n",
    "cluster_indexes = [[] for _ in range(number_of_clusters)]\n",
    "\n",
    "# Populate lists with indexes\n",
    "for i, cluster in enumerate(clusters):\n",
    "    cluster_indexes[cluster].append(i)\n",
    "\n",
    "# Assign images to cluster indices\n",
    "for i in range(0,number_of_clusters):\n",
    "    print(f\"Cluster {i} contains {len(cluster_indexes[i])} images.\")\n",
    "\n",
    "# Create a list of cluster assignments for each vector\n",
    "cluster_labels = [f'Cluster {cluster}' for cluster in clusters]\n",
    "\n",
    "# Printing a portion of dog cluster\n",
    "print(\"Example Images from Dog Cluster Below\")\n",
    "for i in cluster_indexes[15][0:10]:\n",
    "    image_path = image_root+movie_embeddings[i][\"input\"]\n",
    "    display(Image(filename=image_path))\n",
    "\n",
    "# Showing length of dog cluster\n",
    "print(f\"Cluster 15 is the dog cluster, and he appears on screen for about {len(cluster_indexes[15])} seconds.\")\n",
    "\n",
    "# Displaying the scatterplot to see the dog's appearances over time\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x=np.arange(len(movie_embeddings)), y=cluster_labels, palette='bright', hue=cluster_labels, legend='full', s=100)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Cluster')\n",
    "plt.title('Cluster Assignments of Vectors')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Displaying the clustergraph to see where the dogs location was in the earlier clustergraph\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "sns.scatterplot(x=embedded_vectors[:, 0], y=embedded_vectors[:, 1], palette='bright', hue=clusters, legend='full', s=100)\n",
    "for i, vec in enumerate(embedded_vectors):\n",
    "    plt.text(vec[0] + 0.02, vec[1] + 0.02, labels[i], fontsize=6)  # Adding labels\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('t-SNE Embedded Vectors with KMeans Clustering (k=36)')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding yard scenes\n",
    "print(\"Ten Example Images Are Shown Below From The Last Yard Cluster.\")\n",
    "for i in cluster_indexes[33][0:9]:\n",
    "    image_path = image_root+movie_embeddings[i][\"input\"]\n",
    "    display(Image(filename=image_path))\n",
    "\n",
    "# Cluster 0 is one-half a yard cluster\n",
    "yard_clusters_length = round(len(cluster_indexes[0])/2,0)\n",
    "\n",
    "# Clusters 18, 22, and 28 are 80% a yard cluster\n",
    "yard_clusters_length = yard_clusters_length + round(len(cluster_indexes[18])/5*4,0)\n",
    "yard_clusters_length = yard_clusters_length + round(len(cluster_indexes[22])/5*4,0)\n",
    "yard_clusters_length = yard_clusters_length + round(len(cluster_indexes[28])/5*4,0)\n",
    "\n",
    "# Cluster 3, 4, 8, 9, 10, 17, 23, 24, 29, 30, 33 are yard clusters\n",
    "yard_clusters_length += len(cluster_indexes[3])\n",
    "yard_clusters_length += len(cluster_indexes[4])\n",
    "yard_clusters_length += len(cluster_indexes[8])\n",
    "yard_clusters_length += len(cluster_indexes[9])\n",
    "yard_clusters_length += len(cluster_indexes[10])\n",
    "yard_clusters_length += len(cluster_indexes[17])\n",
    "yard_clusters_length += len(cluster_indexes[23])\n",
    "yard_clusters_length += len(cluster_indexes[24])\n",
    "yard_clusters_length += len(cluster_indexes[29])\n",
    "yard_clusters_length += len(cluster_indexes[30])\n",
    "yard_clusters_length += len(cluster_indexes[33])\n",
    "\n",
    "# Cluster 27 contains only a few frames of the shrunken children in the yard, so it's omitted\n",
    "\n",
    "# Printing total time in yard\n",
    "print(f\"The children are in the yard for about {yard_clusters_length} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film Description\n",
    "Our group went with the default choice of \"Honey, I Shrunk the Kids.\" The 1989 movie centers around two sets of siblings who are shrunk by the inventor father's latest invention. One set of children is the inventor's children, Amy and Nick, and the other children are the neighbor's children, Russ and Ron. The children run away from what would be mild dangers for adults but are serious dangers due to their size such as mud puddles and small scorpions. They use whatever they can to give themselves an advantage such a Lego block shelters, ants as transportation, and their dog's amazing hearing ability to finally find and signal to the inventor father who is able to save them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods Summary\n",
    "# This section should highlight methods you used in your exploratory analysis. You should include at least one clustering technique or develop another way to relate frames to other frames. You should also consider dimensionality reduction.\n",
    "We began by removing the opening portion and credits. These have drastically different coloration and would throw off the distances. We kept some of the provided code, so we could see how information changed over time from an arbitrary frame and gained a better understanding of which clusters to explore more thoroughly. For finding the character who appears most often, we tried to take a target frame that centered on each character and found the one with the lowest average distance which turned out to be Ron. Then, we increased the number of clusters until we came across a dog-centered cluster. While there were about five frames containing science images, there were also about five frames throughout the other clusters where the dog was represented. Plots are shown with the new clusters to see when the dog appears in the film temporally and to see how the original clusters changed around the dog. Then, to find the number of images that centered around the children's adventure through the yard, we used the same clusters to see which ones were yard-focused and summed them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hunches and Hypotheses\n",
    "# This section should summarize the questions that you asked about the film that could potentially be answered by exploratory analysis. You should ask at least three questions.\n",
    "1. What images appear most often on screen whether they be characters, settings, or anything else?\n",
    "   H. Since the movie centers around the idea of children being shrunk and finding their way out, they would collectively be the most common image.\n",
    "2. How often do we actually see the dog?\n",
    "   H. The dog probably isn't seen as much as you would think. He is a tool for gags, so we'll see him eating a giant bone or as a plot device, but he otherwise won't come up.\n",
    "3. How long do the children spend adventuring through the yard while shrunken?\n",
    "   H. It's probably about half the movie. The yard prevents a series of dangers, and we already know the children tame an ant to get back to the house, so it's unlikely to not account for a lot of the film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Interpretation\n",
    "# This section should include a summary of your findings. Describe the extent and results of your goal in answering questions.\n",
    "1. There is very little difference in how often the children are shown on screen according to the average distance method. Ron does appear to be seen slightly more than the other children.\n",
    "2. The dog appears sporadically throughout the film, but he appears up front a bit more which may make him seem more prevalent than he is. All total, he only appears for a sum of about two minutes. He appears to exist as a device to shift the mood. The default cluster that was composed of scientific inventions and the dog has now broken into three separate clusters. This includes the new dog cluster and two scientific clusters, one for the inventor doing science and one for the devices.\n",
    "3. The children are in the yard for 1,978 seconds or just under 33 minutes. While it doesn't account for more than half of the film, it does account for the second act."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "# Reflect on your process of analysis. What worked well and did not work well? Describe the limitations of the work and describe what you would work on with more time.\n",
    "Several attempts were made to approach the problems differently. We tried to work with a single-shot detection model in TensorFlow to detect dogs and certain individuals, but there were many configuration issues. An attempt was also made at taking a clipping of the dog target image as an ROI and searching images closer to that, but with the limited number of clusters at the time, they separated more along average color than scene. Also, we tried to sub-divide already divided clusters. All of these techniques didn't work well. They were either too hard to implement given the time constraints, or they didn't provide good answers.\n",
    "\n",
    "Dividing the original embeddings into more clusters worked the best. While this method still seems to divide along average coloration, average coloration serves as a very good proxy for scenes and themes. One cluster even managed to capture the scientist's family's daughter in scenes where she had been soaked. (No one had thought to guess that the coloration of people changes that dramatically when they are wet.)\n",
    "\n",
    "If we had more time, we would have trained a model to use single-shot detection to capture various items throughout the movie to answer the questions such as the Lego block, ant, dog, and children. Also, we would have spent more time seeing how average distance to a target picture is influenced over a movie to make sure that methodology is correct or how it could be improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
